{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex.1 -  Digamos que você treinou cinco modelos diferentes com exatamente os mesmos dados de treinamento e todos alcançam 95% de precisão, existe alguma chance de você poder combinar esses modelos para obter melhores resultados? Se sim, como? Se não, por que?**\n",
    "\n",
    "R: Tem uma change de combinar esse modelo , criando um classificador por votos de maioria , um classificador de votação, funciona melhor se os modelos forem muito diferentes (por exemplos, um classificador SVM, uma Arvore de decisão, um de Regresssão Logistica e assim em diante). Se forem treinados em diferentes instancias de treinamento, fica ainda melhor (esse é o objectivo de ensacar (bagging) e colar (pasting ensembles), mas ainda funcionara caso não sejam treinados, desde que os modelos sejam muito diferentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex.2 - Qual é a diferença entre classificadores de votação rígida e suave?**\n",
    "\n",
    "R: Classificadores de votação rígida (ou votação majoritaria ) cada classificaficador efetua a sua votação a classe que receber maior numero de voltos sera a escolhida, a classificação suave só pode ser feita quando todos os seus classificadores poderem calcular probabilidades para os resultados.Isso da votos de alta confiança, mas peso e geralmente tem melhor desempenho, mas funciona somente se cada classificador for capaz de estimar as probabilidades das classse (por exemplo, para os classiciadores SVM no Scikit-Learn, voce deve configurar probability=True.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex.3 -  É possível acelerar o treinamento de um *bagging ensemble* distribuindo-o por vários servidores? E quanto ao *pasting ensemble* ou *floresta aleatória*?**\n",
    "\n",
    "R:Sim é possivel acelerar o treinamento de um **bagging ensemble** ditribuido por varios servidores assim como **pasting ensemble** , todos os preditores podem ser treinados em diferentes subconjuntos aleatorios de conjunto de treinamento , permitindo que as instancias de treinamento sejam amostradas varias vezes em varios preditores,ja que cada preditores no conjunto é independente dos outros. \n",
    "Quanto ao **Floresta Aleatória** voce pode treinar um conjunto de classificadores de arvores de decisão cada um em um subconjunto aleatório diferente de conjunto de treinamento para fazer previsões devemos obte-las de todas as arvores individuias e , então prever a classe que obtem a maioria dos votos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex.4 - Qual é o benefício da avaliação out-of-bag?**\n",
    "\n",
    "R: A avalição out-of-bag cada previsor em um bagging ensemble é avaliado com a utilização de instâncias nas quais ele não não foi treinado (eles forma mantidos de fora),possibikitando uma avaliação de instâncias bastantes imparcial do ensemble sem a necessidade de um ensemble adicional de avaliação banstante umaprcial do ensemble sema a necessidadde de um ensemble adicional de validação. Assim , voce tem mas instancias disponiveis para treinamento, e seu ensemble pode ter um desempenho melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex.5 - O que torna as árvores-extras ( extra-trees ) mais aleatórias do que as florestas aleatórias comuns? Como essa aleatoriedade extra pode ajudar? As árvores-extras são mais lentas ou mais rápidas que as florestas aleatórias comuns?**\n",
    "\n",
    "R: O que torna as árvores-Extras mais aleatórias do que as florestas aleatórias comuns é a utilização dos limiares alatórios para cada caracteristicas em vez de buscar pelo melhor limiar possivel. \n",
    "\n",
    "Essa aleatóridade extra pode ajudar trocando os viés por uma variância menor, O que torna o treinamento das arvores extras mas rápido , ja que encontrar o melhor limiar possível para cada caracteristicas em cada nó é uma das tarefas que mas demandam tempo no desenvolvimento de uma arvore. \n",
    "\n",
    "As árvores Extras são muito mas rapidas que as florestas aleatorias comuns pois elas não buscam os melhores limiares posssiveis , mas no entanto quando fazem previsões, elas não são nem mais rápidas nem mais lentas que as florestas aleatórias.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
